{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9514700,"sourceType":"datasetVersion","datasetId":5792202}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-14T07:50:32.935693Z","iopub.execute_input":"2024-10-14T07:50:32.936085Z","iopub.status.idle":"2024-10-14T07:50:33.292507Z","shell.execute_reply.started":"2024-10-14T07:50:32.936045Z","shell.execute_reply":"2024-10-14T07:50:33.291508Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/classification-dataset/Combined_Data(3000).csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers datasets evaluate accelerate","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:50:33.635298Z","iopub.execute_input":"2024-10-14T07:50:33.635748Z","iopub.status.idle":"2024-10-14T07:50:46.456140Z","shell.execute_reply.started":"2024-10-14T07:50:33.635711Z","shell.execute_reply":"2024-10-14T07:50:46.455127Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.0)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:50:46.458061Z","iopub.execute_input":"2024-10-14T07:50:46.458396Z","iopub.status.idle":"2024-10-14T07:50:46.757681Z","shell.execute_reply.started":"2024-10-14T07:50:46.458355Z","shell.execute_reply":"2024-10-14T07:50:46.756826Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abc0abc6219f48418f113dffce769c9f"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:51:18.945404Z","iopub.execute_input":"2024-10-14T07:51:18.945790Z","iopub.status.idle":"2024-10-14T07:51:18.950525Z","shell.execute_reply.started":"2024-10-14T07:51:18.945749Z","shell.execute_reply":"2024-10-14T07:51:18.949455Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:51:19.447523Z","iopub.execute_input":"2024-10-14T07:51:19.447919Z","iopub.status.idle":"2024-10-14T07:51:24.641094Z","shell.execute_reply.started":"2024-10-14T07:51:19.447865Z","shell.execute_reply":"2024-10-14T07:51:24.639745Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6ee77cc934d4aa1b45f12bc2970bf2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"846050158a9e440488df1e5c16216424"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"084cac9d5daa44029bb88b6ed97d28b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eb6e8c55ed64d8499ecee4e6ca96d30"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import DatasetDict, Dataset\n\n# Step 1: Load CSV files\ntrain_df = pd.read_csv('/kaggle/input/classification-dataset/Combined_Data(3000).csv')  # Replace with your train file path\ntest_df = pd.read_csv('/kaggle/input/classification-dataset/Combined_Data(3000).csv')    #\n\n# Step 2: Define the label encoding\nlabel_encoding = {\"Education\": 0, \"Finance\": 1, \"Legal\": 2, \"Medical\": 3}\n\n# Replace the label column in both train and test DataFrames\ntrain_df['Label'] = train_df['Label'].replace(label_encoding)\ntest_df['Label'] = test_df['Label'].replace(label_encoding)\n\n# Step 3: Convert DataFrames to Hugging Face Datasets\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\n\n\n\n\n# Step 4: Create a DatasetDict\ndataset_dict = DatasetDict({\n    'train': train_dataset,\n    'test': test_dataset\n})","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:51:42.240245Z","iopub.execute_input":"2024-10-14T07:51:42.241036Z","iopub.status.idle":"2024-10-14T07:51:43.194797Z","shell.execute_reply.started":"2024-10-14T07:51:42.240993Z","shell.execute_reply":"2024-10-14T07:51:43.193747Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3965881142.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train_df['Label'] = train_df['Label'].replace(label_encoding)\n/tmp/ipykernel_30/3965881142.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  test_df['Label'] = test_df['Label'].replace(label_encoding)\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_dict","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:51:47.735610Z","iopub.execute_input":"2024-10-14T07:51:47.736021Z","iopub.status.idle":"2024-10-14T07:51:47.743091Z","shell.execute_reply.started":"2024-10-14T07:51:47.735981Z","shell.execute_reply":"2024-10-14T07:51:47.742113Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Sentences', 'Label'],\n        num_rows: 12000\n    })\n    test: Dataset({\n        features: ['Sentences', 'Label'],\n        num_rows: 12000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"Sentences\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:51:48.849282Z","iopub.execute_input":"2024-10-14T07:51:48.849676Z","iopub.status.idle":"2024-10-14T07:51:48.854182Z","shell.execute_reply.started":"2024-10-14T07:51:48.849637Z","shell.execute_reply":"2024-10-14T07:51:48.853186Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = dataset_dict.map(preprocess_function, batched=True)\n\n# Drop the unwanted column from the training dataset\ntrain_dataset = tokenized_dataset['train']\n\n# Convert to pandas DataFrame, drop the column, and convert back\ntrain_df = train_dataset.to_pandas().drop(columns=['Sentences'])\ntrain_dataset = Dataset.from_pandas(train_df)\n\n# Update the DatasetDict\ntokenized_dataset['train'] = train_dataset\n\n\n\n\n\n# Drop the unwanted column from the training dataset\ntest_dataset = tokenized_dataset['test']\n\n# Convert to pandas DataFrame, drop the column, and convert back\ntest_df = test_dataset.to_pandas().drop(columns=['Sentences'])\ntest_dataset = Dataset.from_pandas(test_df)\n\n# Update the DatasetDict\ntokenized_dataset['test'] = test_dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:58:51.548159Z","iopub.execute_input":"2024-10-14T07:58:51.548544Z","iopub.status.idle":"2024-10-14T07:58:57.218880Z","shell.execute_reply.started":"2024-10-14T07:58:51.548506Z","shell.execute_reply":"2024-10-14T07:58:57.217965Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d3520ea231a4fce84e3dcb1e1621f95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1be0a61cf9246bd9862e6f8a53d67bd"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset\n\n# Rename the \"Label\" column to \"label\" in the training dataset\ndef rename_label(example):\n    example['label'] = example.pop('Label')\n    return example\n\ntokenized_dataset['train'] = tokenized_dataset['train'].map(rename_label)\ntokenized_dataset['test'] = tokenized_dataset['test'].map(rename_label)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T08:47:44.697696Z","iopub.execute_input":"2024-10-14T08:47:44.698358Z","iopub.status.idle":"2024-10-14T08:47:46.310135Z","shell.execute_reply.started":"2024-10-14T08:47:44.698317Z","shell.execute_reply":"2024-10-14T08:47:46.309273Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8a0357d77844bd79141ef7c67a8186d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b050c370035a438f9496034543066ff2"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-10-14T08:48:14.847198Z","iopub.execute_input":"2024-10-14T08:48:14.847600Z","iopub.status.idle":"2024-10-14T08:48:14.856522Z","shell.execute_reply.started":"2024-10-14T08:48:14.847558Z","shell.execute_reply":"2024-10-14T08:48:14.855656Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101,\n  2061,\n  2096,\n  2327,\n  4177,\n  1999,\n  2859,\n  1010,\n  1999,\n  1996,\n  2822,\n  2231,\n  2024,\n  5204,\n  1997,\n  2311,\n  1010,\n  2024,\n  5204,\n  1997,\n  8915,\n  2232,\n  5197,\n  1997,\n  2311,\n  1037,\n  2614,\n  3423,\n  7705,\n  2005,\n  20014,\n  4402,\n  2571,\n  6593,\n  8787,\n  3200,\n  3860,\n  1010,\n  7285,\n  2320,\n  2153,\n  1010,\n  2926,\n  2012,\n  1996,\n  2334,\n  2504,\n  1010,\n  2038,\n  2000,\n  2022,\n  5301,\n  1010,\n  9839,\n  1012,\n  102],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1],\n 'label': 0}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:51:54.872885Z","iopub.execute_input":"2024-10-14T07:51:54.873222Z","iopub.status.idle":"2024-10-14T07:52:06.929455Z","shell.execute_reply.started":"2024-10-14T07:51:54.873187Z","shell.execute_reply":"2024-10-14T07:52:06.928425Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\naccuracy = evaluate.load(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:52:06.930812Z","iopub.execute_input":"2024-10-14T07:52:06.931591Z","iopub.status.idle":"2024-10-14T07:52:09.613995Z","shell.execute_reply.started":"2024-10-14T07:52:06.931533Z","shell.execute_reply":"2024-10-14T07:52:09.613080Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5ca7d269e8c414b8d91e8798e87fe71"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:52:09.615949Z","iopub.execute_input":"2024-10-14T07:52:09.616516Z","iopub.status.idle":"2024-10-14T07:52:09.621529Z","shell.execute_reply.started":"2024-10-14T07:52:09.616481Z","shell.execute_reply":"2024-10-14T07:52:09.620507Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"id2label = {0: \"Education\", 1: \"Finance\", 2: \"Legal\", 3:\"Medical\"}\nlabel2id = {\"Education\": 0, \"Finance\": 1, \"Legal\":2, \"Medical\":3}","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:52:09.622609Z","iopub.execute_input":"2024-10-14T07:52:09.622869Z","iopub.status.idle":"2024-10-14T07:52:09.632694Z","shell.execute_reply.started":"2024-10-14T07:52:09.622839Z","shell.execute_reply":"2024-10-14T07:52:09.631854Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\nimport torch\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=4, id2label=id2label, label2id=label2id\n)\n\n# # # Load model directly\n# # Load model directly\n# from transformers import AutoTokenizer, AutoModelForMaskedLM\n\n# # tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n# model = AutoModelForMaskedLM.from_pretrained(\"google-bert/bert-base-uncased\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T08:48:33.791799Z","iopub.execute_input":"2024-10-14T08:48:33.792631Z","iopub.status.idle":"2024-10-14T08:48:34.049030Z","shell.execute_reply.started":"2024-10-14T08:48:33.792589Z","shell.execute_reply":"2024-10-14T08:48:34.048295Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-10-14T07:52:12.254046Z","iopub.execute_input":"2024-10-14T07:52:12.254367Z","iopub.status.idle":"2024-10-14T07:52:12.258400Z","shell.execute_reply.started":"2024-10-14T07:52:12.254333Z","shell.execute_reply":"2024-10-14T07:52:12.257533Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2024-10-14T08:48:39.411528Z","iopub.execute_input":"2024-10-14T08:48:39.411922Z","iopub.status.idle":"2024-10-14T08:48:39.418435Z","shell.execute_reply.started":"2024-10-14T08:48:39.411872Z","shell.execute_reply":"2024-10-14T08:48:39.417482Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'label'],\n    num_rows: 12000\n})"},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"my_classifer_Model\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n    report_to = ['none']\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator\n#     compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T08:48:41.942269Z","iopub.execute_input":"2024-10-14T08:48:41.942989Z","iopub.status.idle":"2024-10-14T08:58:24.212528Z","shell.execute_reply.started":"2024-10-14T08:48:41.942950Z","shell.execute_reply":"2024-10-14T08:58:24.211619Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 09:41, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.130000</td>\n      <td>0.037523</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.011800</td>\n      <td>0.002576</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1500, training_loss=0.05929474449157715, metrics={'train_runtime': 581.7653, 'train_samples_per_second': 41.254, 'train_steps_per_second': 2.578, 'total_flos': 2254551347516160.0, 'train_loss': 0.05929474449157715, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\ntext = \"These free-text notes include physician and nursing notes, radiology, and pathology reports. Prior to bringing in a note type, the notes are de-identified. There are two steps in our de-identification framework: notes de-identification and notes adjudication\"\n\nclassifier = pipeline(\"text-classification\", model= \"/kaggle/working/my_classifer_Model/checkpoint-1500\")\nclassifier(text)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T09:07:22.522986Z","iopub.execute_input":"2024-10-14T09:07:22.523637Z","iopub.status.idle":"2024-10-14T09:07:22.728948Z","shell.execute_reply.started":"2024-10-14T09:07:22.523595Z","shell.execute_reply":"2024-10-14T09:07:22.728071Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[{'label': 'Medical', 'score': 0.6921417713165283}]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}